{"metadata":{"colab":{"provenance":[],"mount_file_id":"15WMlsxsnu1mkaCDMyP4tGjlGavrUE72z","authorship_tag":"ABX9TyOcNTCwSywWqUeqxxYw2aQI","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/sofiammatias/tick-tick-bloom/blob/main/tick_tick_bloom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"markdown","source":"# Tick Tick Bloom Challenge (Driven Data)\nThe goal in this challenge is to use satellite imagery to detect and classify the severity of cyanobacteria blooms in small, inland water bodies. The resulting algorithm will help water quality managers better allocate resources for in situ sampling, and make more informed decisions around public health warnings for critical resources like drinking water reservoirs. Ultimately, more accurate and more timely detection of algal blooms helps keep both the human and marine life that rely on these water bodies safe and healthy.","metadata":{"id":"U9l6qB_D-lku"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"XtOqi3MS-8ux"}},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/sentence-transformer-package/sentence-transformers-2.2.2/sentence-transformers-2.2.2\") \nimport odc.stac","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install odc-stac\n!pip install geopandas","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixCXxY_-_8Y3","outputId":"b66f969a-532c-40a2-fcf3-f898c4f8ecc3","execution":{"iopub.status.busy":"2023-01-29T04:21:38.850279Z","iopub.execute_input":"2023-01-29T04:21:38.850922Z","iopub.status.idle":"2023-01-29T04:21:54.037171Z","shell.execute_reply.started":"2023-01-29T04:21:38.850880Z","shell.execute_reply":"2023-01-29T04:21:54.035781Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting odc-stac\n  Using cached odc_stac-0.2.4-py3-none-any.whl (32 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from odc-stac) (1.21.6)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.7/site-packages (from odc-stac) (0.11.2)\nRequirement already satisfied: affine in /opt/conda/lib/python3.7/site-packages (from odc-stac) (2.4.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from odc-stac) (3.1.2)\nRequirement already satisfied: xarray>=0.19 in /opt/conda/lib/python3.7/site-packages (from odc-stac) (0.20.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from odc-stac) (1.3.5)\nRequirement already satisfied: pystac<2,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from odc-stac) (1.5.0)\nCollecting datacube>=1.8.5\n  Using cached datacube-1.8.5-py2.py3-none-any.whl (271 kB)\nRequirement already satisfied: cloudpickle>=0.4 in /opt/conda/lib/python3.7/site-packages (from datacube>=1.8.5->odc-stac) (2.1.0)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.7/site-packages (from datacube>=1.8.5->odc-stac) (4.6.1)\nRequirement already satisfied: distributed in /opt/conda/lib/python3.7/site-packages (from datacube>=1.8.5->odc-stac) (2022.2.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from datacube>=1.8.5->odc-stac) (6.0)\nCollecting psycopg2\n  Using cached psycopg2-2.9.5.tar.gz (384 kB)\n  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[23 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m running egg_info\n  \u001b[31m   \u001b[0m creating /tmp/pip-pip-egg-info-4g7f17r_/psycopg2.egg-info\n  \u001b[31m   \u001b[0m writing /tmp/pip-pip-egg-info-4g7f17r_/psycopg2.egg-info/PKG-INFO\n  \u001b[31m   \u001b[0m writing dependency_links to /tmp/pip-pip-egg-info-4g7f17r_/psycopg2.egg-info/dependency_links.txt\n  \u001b[31m   \u001b[0m writing top-level names to /tmp/pip-pip-egg-info-4g7f17r_/psycopg2.egg-info/top_level.txt\n  \u001b[31m   \u001b[0m writing manifest file '/tmp/pip-pip-egg-info-4g7f17r_/psycopg2.egg-info/SOURCES.txt'\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m Error: pg_config executable not found.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m pg_config is required to build psycopg2 from source.  Please add the directory\n  \u001b[31m   \u001b[0m containing pg_config to the $PATH or specify the full executable path with the\n  \u001b[31m   \u001b[0m option:\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m     python setup.py build_ext --pg-config /path/to/pg_config build ...\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m or with the pg_config option in 'setup.cfg'.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m If you prefer to avoid building psycopg2 from source, please install the PyPI\n  \u001b[31m   \u001b[0m 'psycopg2-binary' package instead.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m For further information please check the 'doc/src/install.rst' file (also at\n  \u001b[31m   \u001b[0m <https://www.psycopg.org/docs/install.html>).\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25hRequirement already satisfied: geopandas in /opt/conda/lib/python3.7/site-packages (0.10.2)\nRequirement already satisfied: shapely>=1.6 in /opt/conda/lib/python3.7/site-packages (from geopandas) (1.8.0)\nRequirement already satisfied: pandas>=0.25.0 in /opt/conda/lib/python3.7/site-packages (from geopandas) (1.3.5)\nRequirement already satisfied: pyproj>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from geopandas) (3.1.0)\nRequirement already satisfied: fiona>=1.8 in /opt/conda/lib/python3.7/site-packages (from geopandas) (1.8.22)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from fiona>=1.8->geopandas) (2.5.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from fiona>=1.8->geopandas) (59.8.0)\nRequirement already satisfied: six>=1.7 in /opt/conda/lib/python3.7/site-packages (from fiona>=1.8->geopandas) (1.15.0)\nRequirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.7/site-packages (from fiona>=1.8->geopandas) (0.7.2)\nRequirement already satisfied: click>=4.0 in /opt/conda/lib/python3.7/site-packages (from fiona>=1.8->geopandas) (8.1.3)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from fiona>=1.8->geopandas) (2022.12.7)\nRequirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.7/site-packages (from fiona>=1.8->geopandas) (1.1.1)\nRequirement already satisfied: attrs>=17 in /opt/conda/lib/python3.7/site-packages (from fiona>=1.8->geopandas) (21.4.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.25.0->geopandas) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.25.0->geopandas) (2022.1)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.25.0->geopandas) (1.21.6)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=4.0->fiona>=1.8->geopandas) (6.0.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=4.0->fiona>=1.8->geopandas) (3.8.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install planetary_computer\n!pip install pystac_client","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miG6Vnu18LBW","outputId":"c837d2ab-63d1-41a0-96ea-945df487574b","execution":{"iopub.status.busy":"2023-01-29T04:13:03.999977Z","iopub.execute_input":"2023-01-29T04:13:04.000371Z","iopub.status.idle":"2023-01-29T04:13:29.648576Z","shell.execute_reply.started":"2023-01-29T04:13:04.000337Z","shell.execute_reply":"2023-01-29T04:13:29.647367Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting planetary_computer\n  Downloading planetary_computer-0.4.9-py3-none-any.whl (17 kB)\nRequirement already satisfied: click>=7.1 in /opt/conda/lib/python3.7/site-packages (from planetary_computer) (8.1.3)\nRequirement already satisfied: pydantic[dotenv]>=1.7.3 in /opt/conda/lib/python3.7/site-packages (from planetary_computer) (1.8.2)\nCollecting pystac>=1.0.0\n  Using cached pystac-1.5.0-py3-none-any.whl (146 kB)\nRequirement already satisfied: requests>=2.25.1 in /opt/conda/lib/python3.7/site-packages (from planetary_computer) (2.28.1)\nRequirement already satisfied: pytz>=2020.5 in /opt/conda/lib/python3.7/site-packages (from planetary_computer) (2022.1)\nCollecting pystac-client>=0.2.0\n  Downloading pystac_client-0.5.1-py3-none-any.whl (29 kB)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.1->planetary_computer) (6.0.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from pydantic[dotenv]>=1.7.3->planetary_computer) (4.1.1)\nRequirement already satisfied: python-dotenv>=0.10.4 in /opt/conda/lib/python3.7/site-packages (from pydantic[dotenv]>=1.7.3->planetary_computer) (0.21.1)\nRequirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.7/site-packages (from pystac>=1.0.0->planetary_computer) (2.8.2)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.25.1->planetary_computer) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.25.1->planetary_computer) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.25.1->planetary_computer) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.25.1->planetary_computer) (2022.12.7)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.0->pystac>=1.0.0->planetary_computer) (1.15.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=7.1->planetary_computer) (3.8.0)\nInstalling collected packages: pystac, pystac-client, planetary_computer\nSuccessfully installed planetary_computer-0.4.9 pystac-1.5.0 pystac-client-0.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pystac_client in /opt/conda/lib/python3.7/site-packages (0.5.1)\nRequirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/lib/python3.7/site-packages (from pystac_client) (2.8.2)\nRequirement already satisfied: requests>=2.27.1 in /opt/conda/lib/python3.7/site-packages (from pystac_client) (2.28.1)\nRequirement already satisfied: pystac>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from pystac_client) (1.5.0)\nRequirement already satisfied: typing-extensions>=3.7 in /opt/conda/lib/python3.7/site-packages (from pystac>=1.4.0->pystac_client) (4.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.0->pystac_client) (1.15.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.27.1->pystac_client) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.27.1->pystac_client) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.27.1->pystac_client) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.27.1->pystac_client) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install rioxarray","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WeUiJwV7js5Y","outputId":"b8aee3dc-ee4d-4f63-c117-920fe6183104","execution":{"iopub.status.busy":"2023-01-29T04:13:29.650395Z","iopub.execute_input":"2023-01-29T04:13:29.650907Z","iopub.status.idle":"2023-01-29T04:13:59.917967Z","shell.execute_reply.started":"2023-01-29T04:13:29.650865Z","shell.execute_reply":"2023-01-29T04:13:59.916281Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting rioxarray\n  Downloading rioxarray-0.9.1.tar.gz (47 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m206.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: xarray>=0.17 in /opt/conda/lib/python3.7/site-packages (from rioxarray) (0.20.2)\nRequirement already satisfied: pyproj>=2.2 in /opt/conda/lib/python3.7/site-packages (from rioxarray) (3.1.0)\nRequirement already satisfied: rasterio in /opt/conda/lib/python3.7/site-packages (from rioxarray) (1.2.10)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from rioxarray) (23.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from pyproj>=2.2->rioxarray) (2022.12.7)\nRequirement already satisfied: numpy>=1.18 in /opt/conda/lib/python3.7/site-packages (from xarray>=0.17->rioxarray) (1.21.6)\nRequirement already satisfied: typing-extensions>=3.7 in /opt/conda/lib/python3.7/site-packages (from xarray>=0.17->rioxarray) (4.1.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from xarray>=0.17->rioxarray) (6.0.0)\nRequirement already satisfied: pandas>=1.1 in /opt/conda/lib/python3.7/site-packages (from xarray>=0.17->rioxarray) (1.3.5)\nRequirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.7/site-packages (from rasterio->rioxarray) (0.7.2)\nRequirement already satisfied: click-plugins in /opt/conda/lib/python3.7/site-packages (from rasterio->rioxarray) (1.1.1)\nRequirement already satisfied: affine in /opt/conda/lib/python3.7/site-packages (from rasterio->rioxarray) (2.4.0)\nRequirement already satisfied: click>=4.0 in /opt/conda/lib/python3.7/site-packages (from rasterio->rioxarray) (8.1.3)\nRequirement already satisfied: snuggs>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from rasterio->rioxarray) (1.4.7)\nRequirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from rasterio->rioxarray) (21.4.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from rasterio->rioxarray) (59.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1->xarray>=0.17->rioxarray) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=1.1->xarray>=0.17->rioxarray) (2022.1)\nRequirement already satisfied: pyparsing>=2.1.6 in /opt/conda/lib/python3.7/site-packages (from snuggs>=1.4.1->rasterio->rioxarray) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->xarray>=0.17->rioxarray) (3.8.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.1->xarray>=0.17->rioxarray) (1.15.0)\nBuilding wheels for collected packages: rioxarray\n  Building wheel for rioxarray (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rioxarray: filename=rioxarray-0.9.1-py3-none-any.whl size=54591 sha256=cf4da307b018955ca0ee9eb84eb562cd39d63d5b237bb398c23ddde97ae557aa\n  Stored in directory: /root/.cache/pip/wheels/07/da/9e/1cc57b2e7a29a206893db83e984a341e2e94378263e0798229\nSuccessfully built rioxarray\nInstalling collected packages: rioxarray\nSuccessfully installed rioxarray-0.9.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"id":"RZTEo4uX-TM_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de39e60e-7fa4-4211-b47f-f142acec5bfd","execution":{"iopub.status.busy":"2023-01-29T04:13:59.921181Z","iopub.execute_input":"2023-01-29T04:13:59.921659Z","iopub.status.idle":"2023-01-29T04:13:59.978861Z","shell.execute_reply.started":"2023-01-29T04:13:59.921622Z","shell.execute_reply":"2023-01-29T04:13:59.977645Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nfrom datetime import timedelta\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport odc.stac\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nimport geopandas as gpd\nfrom shapely.geometry import Point\nimport geopy.distance as distance\nimport rioxarray\nfrom IPython.display import Image\nfrom PIL import Image as PILImage\nimport planetary_computer as pc\nfrom pystac_client import Client\n\n%matplotlib inline","metadata":{"id":"2c5Jkbrz-7Ua","execution":{"iopub.status.busy":"2023-01-29T04:20:14.939133Z","iopub.execute_input":"2023-01-29T04:20:14.939756Z","iopub.status.idle":"2023-01-29T04:20:14.987520Z","shell.execute_reply.started":"2023-01-29T04:20:14.939710Z","shell.execute_reply":"2023-01-29T04:20:14.986359Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/975136563.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0modc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'odc'"],"ename":"ModuleNotFoundError","evalue":"No module named 'odc'","output_type":"error"}]},{"cell_type":"markdown","source":"# Data: Collection and EDA","metadata":{"id":"0vOdXkVS_XmA"}},{"cell_type":"code","source":"data_path = \"/kaggle/input/tick-tick-bloom-challenge/\"\nwork_path = \"/kaggle/working/\"\nmetadata_file = f'{data_path}metadata.csv'\nmetadata = pd.read_csv(metadata_file)","metadata":{"id":"Ho17ffF7BJLy","execution":{"iopub.status.busy":"2023-01-29T04:14:00.211828Z","iopub.status.idle":"2023-01-29T04:14:00.212608Z","shell.execute_reply.started":"2023-01-29T04:14:00.212350Z","shell.execute_reply":"2023-01-29T04:14:00.212374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metadata.csv","metadata":{"id":"N-ophUM1S7o2"}},{"cell_type":"markdown","source":"### Location","metadata":{"id":"MpA2lEDfEwEn"}},{"cell_type":"code","source":"display(metadata.head())\nmetadata.split.value_counts(dropna=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"4YNcTs46DoMz","outputId":"76175590-fb20-428d-807a-561fccb6d60d","execution":{"iopub.status.busy":"2023-01-29T04:14:00.213580Z","iopub.status.idle":"2023-01-29T04:14:00.214010Z","shell.execute_reply.started":"2023-01-29T04:14:00.213807Z","shell.execute_reply":"2023-01-29T04:14:00.213826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the default geopandas base map file to plot points on\nworld = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n\nfig, ax = plt.subplots(figsize=(15, 6))\n\n# map the training data\nbase = world[world.name == \"United States of America\"].plot(\n    edgecolor=\"gray\", color=\"ghostwhite\", figsize=(9, 4), alpha=0.3, ax=ax\n)\ntrain_meta = metadata[metadata[\"split\"] == \"train\"]\ngeometry = [Point(xy) for xy in zip(train_meta[\"longitude\"], train_meta[\"latitude\"])]\ngdf = gpd.GeoDataFrame(train_meta, geometry=geometry)\ngdf.plot(ax=base, marker=\".\", markersize=3, color=\"blue\", label=\"Train\", alpha=0.6)\n\n# map the test data\ntest_meta = metadata[metadata[\"split\"] == \"test\"]\ngeometry = [Point(xy) for xy in zip(test_meta[\"longitude\"], test_meta[\"latitude\"])]\ngdf = gpd.GeoDataFrame(test_meta, geometry=geometry)\ngdf.plot(ax=base, marker=\".\", markersize=3, color=\"orange\", label=\"Test\", alpha=0.6)\n\nplt.xlabel(\"Longitude\")\nplt.ylabel(\"Latitude\")\nplt.xlim([-125, -65])\nplt.ylim([25, 50])\nplt.legend(loc=4, markerscale=3)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"nBQ0TJMvDvkq","outputId":"b76396b7-b4f2-4f9e-f0cb-8fc208e64c77","execution":{"iopub.status.busy":"2023-01-29T04:14:00.217070Z","iopub.status.idle":"2023-01-29T04:14:00.217525Z","shell.execute_reply.started":"2023-01-29T04:14:00.217316Z","shell.execute_reply":"2023-01-29T04:14:00.217336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Date","metadata":{"id":"fjGGk9rGEzUn"}},{"cell_type":"code","source":"# convert date to pd.datetime\nmetadata.date = pd.to_datetime(metadata.date)\n\n# what is the date range?\ndisplay (metadata.groupby(\"split\").agg(min_date=(\"date\", min), max_date=(\"date\", max)))\n\n# what years are in the data?\npd.crosstab(metadata.date.dt.year, metadata.split).plot(kind=\"bar\")\nplt.ylabel(\"Number of samples\")\nplt.xlabel(\"Year\")\nplt.title(\"Distribution of years in the data\")\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"id":"fECfhyT-Ea52","outputId":"7fb033d7-ef59-4c5e-b244-5a6dcaa34868","execution":{"iopub.status.busy":"2023-01-29T04:14:00.219517Z","iopub.status.idle":"2023-01-29T04:14:00.219988Z","shell.execute_reply.started":"2023-01-29T04:14:00.219785Z","shell.execute_reply":"2023-01-29T04:14:00.219805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# what seasons are the data points from?\nmetadata[\"season\"] = (\n    metadata.date.dt.month.replace([12, 1, 2], \"winter\")\n    .replace([3, 4, 5], \"spring\")\n    .replace([6, 7, 8], \"summer\")\n    .replace([9, 10, 11], \"fall\")\n)\nprint ('Seasons')\ndisplay(metadata.season.value_counts())\n\n# where is data from for each season?\nfig, axes = plt.subplots(2, 2, figsize=(20, 10))\n\nfor season, ax in zip(metadata.season.unique(), axes.flatten()):\n    base = world[world.name == \"United States of America\"].plot(\n        edgecolor=\"gray\", color=\"ghostwhite\", alpha=0.3, ax=ax\n    )\n\n    sub = metadata[metadata.season == season]\n    geometry = [Point(xy) for xy in zip(sub[\"longitude\"], sub[\"latitude\"])]\n    gdf = gpd.GeoDataFrame(sub, geometry=geometry)\n    gdf.plot(ax=base, marker=\".\", markersize=2.5)\n    ax.set_xlim([-125, -66])\n    ax.set_ylim([25, 50])\n    ax.set_title(f\"{season.capitalize()} data points\")\n    ax.axis(\"off\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":662},"id":"ogwdzvTDFbue","outputId":"6c3d65fd-3dae-4b72-db64-f4af246de934","execution":{"iopub.status.busy":"2023-01-29T04:14:00.221303Z","iopub.status.idle":"2023-01-29T04:14:00.222104Z","shell.execute_reply.started":"2023-01-29T04:14:00.221817Z","shell.execute_reply":"2023-01-29T04:14:00.221852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Labels.csv","metadata":{"id":"yleDRsATSzqZ"}},{"cell_type":"code","source":"train_labels_file = f'{data_path}train_labels.csv'\ntrain_labels = pd.read_csv(train_labels_file)","metadata":{"id":"cxNT05dpLJ3_","execution":{"iopub.status.busy":"2023-01-29T04:14:00.223960Z","iopub.status.idle":"2023-01-29T04:14:00.224375Z","shell.execute_reply.started":"2023-01-29T04:14:00.224180Z","shell.execute_reply":"2023-01-29T04:14:00.224199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_labels.head())\ntrain_labels.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"EbQ646QkSyjC","outputId":"21a36c1b-7017-44ad-973d-7ef306750df7","execution":{"iopub.status.busy":"2023-01-29T04:14:00.225491Z","iopub.status.idle":"2023-01-29T04:14:00.225938Z","shell.execute_reply.started":"2023-01-29T04:14:00.225741Z","shell.execute_reply":"2023-01-29T04:14:00.225761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels_and_metadata = train_labels.merge(\n    metadata, how=\"left\", left_on=\"uid\", right_on=\"uid\", validate=\"1:1\"\n)\ntrain_labels_and_metadata","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"N3aO5fsvTJib","outputId":"228ed447-98e4-46a1-eb65-767bbb656c3a","execution":{"iopub.status.busy":"2023-01-29T04:14:00.227457Z","iopub.status.idle":"2023-01-29T04:14:00.227905Z","shell.execute_reply.started":"2023-01-29T04:14:00.227706Z","shell.execute_reply":"2023-01-29T04:14:00.227726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"severity_counts = (\n    train_labels.replace(\n        {\n            \"severity\": {\n                1: \"1 (<20,000)\",\n                2: \"2 (20,000-100,000)\",\n                3: \"3 (100,000 - 1,000,000)\",\n                4: \"4 (1,00,000 - 10,000,000)\",\n                5: \"5 (>10,000,00)\",\n            }\n        }\n    )\n    .severity.value_counts()\n    .sort_index(ascending=False)\n)\nplt.barh(severity_counts.index, severity_counts.values)\nplt.xlabel(\"Number of samples\")\nplt.ylabel(\"Severity (range in cells/mL)\")\nplt.title(\"Train labels severity level counts\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"zyPYbbg-xpn9","outputId":"b0e5ff76-27a7-4097-eba1-b80d5bc35684","execution":{"iopub.status.busy":"2023-01-29T04:14:00.230036Z","iopub.status.idle":"2023-01-29T04:14:00.230998Z","shell.execute_reply.started":"2023-01-29T04:14:00.230769Z","shell.execute_reply":"2023-01-29T04:14:00.230791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.density.describe()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sMXy6hZylJl","outputId":"2603a777-4631-42ee-c159-6f886d65f7ef","execution":{"iopub.status.busy":"2023-01-29T04:14:00.232377Z","iopub.status.idle":"2023-01-29T04:14:00.232826Z","shell.execute_reply.started":"2023-01-29T04:14:00.232625Z","shell.execute_reply":"2023-01-29T04:14:00.232648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Process Feature Data","metadata":{"id":"hw8lDwAp7OKA"}},{"cell_type":"markdown","source":"Feature data is not provided directly. Instead, access to all feature data can only be done through **external, publicly available APIs**. Relevant imagery can be identified using the location and date of each sample, listed in metadata.csv.\n\nPull in matching satellite imagery will be done using Microsoft's Planetary Computer. Use only **Sentinel-2 L2A** and **Landsat Level-2** satellite imagery. Sentinel-2 L1C and Landsat Level-1 imagery are also allowed.","metadata":{"id":"59ThW_eF7Ruv"}},{"cell_type":"code","source":"# Establish a connection to the STAC API\n\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\", modifier=pc.sign_inplace\n)","metadata":{"id":"B1CDgsYFynzA","execution":{"iopub.status.busy":"2023-01-29T04:14:00.234815Z","iopub.status.idle":"2023-01-29T04:14:00.235383Z","shell.execute_reply.started":"2023-01-29T04:14:00.235101Z","shell.execute_reply":"2023-01-29T04:14:00.235127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Location range: \nsearch an area with 50,000 meters on either side of our sample point (100,000 m x 100,000 m), to make sure we're pulling in all relevant imagery. This is just a starting point, and you can improve on how to best search for the correct location in the Planetary Computer.","metadata":{"id":"t1FHDwxUeSBu"}},{"cell_type":"markdown","source":"## Time range: \nWe want our feature data to be as close to the time of the sample as possible, because in algal blooms in small water bodies form and move very rapidly. Remember, you cannot use any data collected after the date of the sample.\n\nImagery taken with roughly 10 days of the sample will generally still be an accurate representation of environmental conditions at the time of the sample. For some data points you may not be able to get data within 10 days, and may have to use earlier data. We'll search the fifteen days up to the sample time, including the sample date.","metadata":{"id":"AUHaY9ikgYOr"}},{"cell_type":"markdown","source":"## Select one image\nThe planetary computer returned 46 different items for a ! Let's look at some of the details of the items that were found to match our label.","metadata":{"id":"TGC5Xqa_h5L-"}},{"cell_type":"markdown","source":"To keep things simple, we'll just choose one image to input into our model. Keep in mind that it is possible to incorporate multiple images!\n\nWe'll narrow to one image in two steps:\n\n- If any Sentinel imagery is available, filter to only Sentinel imagery. Sentinel-2 is higher resolution than Landsat, which is extremely helpful for blooms in small water bodies. In this case, two images are from Sentinel and contain the actual sample location.\n- Select the item that is the closest time wise to the sampling date. This gives us a Sentinel-2A item that was captured on 10/20/2022 - two days before our sample was collected on 10/22.\n\nThis is a very simple way to choose the best image. ","metadata":{"id":"d-FIC6Ynim3Z"}},{"cell_type":"markdown","source":"# Functions to sort and get imagery","metadata":{"id":"QEGgRNHLjgaF"}},{"cell_type":"code","source":"# get our bounding box to search latitude and longitude coordinates\ndef get_bounding_box(latitude, longitude, meter_buffer=50000):\n    \"\"\"\n    Given a latitude, longitude, and buffer in meters, returns a bounding\n    box around the point with the buffer on the left, right, top, and bottom.\n\n    Returns a list of [minx, miny, maxx, maxy]\n    \"\"\"\n    distance_search = distance.distance(meters=meter_buffer)\n\n    # calculate the lat/long bounds based on ground distance\n    # bearings are cardinal directions to move (south, west, north, and east)\n    min_lat = distance_search.destination((latitude, longitude), bearing=180)[0]\n    min_long = distance_search.destination((latitude, longitude), bearing=270)[1]\n    max_lat = distance_search.destination((latitude, longitude), bearing=0)[0]\n    max_long = distance_search.destination((latitude, longitude), bearing=90)[1]\n\n    return [min_long, min_lat, max_long, max_lat]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get our date range to search, and format correctly for query\ndef get_date_range(date, time_buffer_days=15):\n    \"\"\"Get a date range to search for in the planetary computer based\n    on a sample's date. The time range will include the sample date\n    and time_buffer_days days prior\n\n    Returns a string\"\"\"\n    datetime_format = \"%Y-%m-%dT\"\n    range_start = pd.to_datetime(date) - timedelta(days=time_buffer_days)\n    date_range = f\"{range_start.strftime(datetime_format)}/{pd.to_datetime(date).strftime(datetime_format)}\"\n\n    return date_rangeBe aware that querying the Planetary Computer for all of the images is going to take a LONG time! You'll want to find ways to both save work as you go, and optimize your code for efficiency.","metadata":{"id":"OVJLYQFznbmD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting processed features","metadata":{}},{"cell_type":"markdown","source":"We'll save out the processed features for each image as we go, to make sure we only have to run time-intensive parts of our code once.\n\nFor time, here we'll train on a randomly selected small subset of the training data. The cell below is highly time intensive, because for each row in the data we have to query the planetary computer catalog and process imagery.\n\nWe'll still include and predict on all of the test data.","metadata":{}},{"cell_type":"code","source":"def select_best_item(items, date, latitude, longitude):\n    \"\"\"\n    Select the best satellite item given a sample's date, latitude, and longitude.\n    If any Sentinel-2 imagery is available, returns the closest sentinel-2 image by\n    time. Otherwise, returns the closest Landsat imagery.\n\n    Returns a tuple of (STAC item, item platform name, item date)\n    \"\"\"\n    # get item details\n    item_details = pd.DataFrame(\n        [\n            {\n                \"datetime\": item.datetime.strftime(\"%Y-%m-%d\"),\n                \"platform\": item.properties[\"platform\"],\n                \"min_long\": item.bbox[0],\n                \"max_long\": item.bbox[2],\n                \"min_lat\": item.bbox[1],\n                \"max_lat\": item.bbox[3],\n                \"item_obj\": item,\n            }\n            for item in items\n        ]\n    )\n\n    # filter to items that contain the point location, or return None if none contain the point\n    item_details[\"contains_sample_point\"] = (\n        (item_details.min_lat < latitude)\n        & (item_details.max_lat > latitude)\n        & (item_details.min_long < longitude)\n        & (item_details.max_long > longitude)\n    )\n    item_details = item_details[item_details[\"contains_sample_point\"] == True]\n    if len(item_details) == 0:\n        return (np.nan, np.nan, np.nan)\n\n    # add time difference between each item and the sample\n    item_details[\"time_diff\"] = pd.to_datetime(date) - pd.to_datetime(\n        item_details[\"datetime\"]\n    )\n\n    # if we have sentinel-2, filter to sentinel-2 images only\n    item_details[\"sentinel\"] = item_details.platform.str.lower().str.contains(\n        \"sentinel\"\n    )\n    if item_details[\"sentinel\"].any():\n        item_details = item_details[item_details[\"sentinel\"] == True]\n\n    # return the closest imagery by time\n    best_item = item_details.sort_values(by=\"time_diff\", ascending=True).iloc[0]\n\n    return (best_item[\"item_obj\"], best_item[\"platform\"], best_item[\"datetime\"])","metadata":{"id":"Lt8kdhH-jmgZ","execution":{"iopub.status.busy":"2023-01-29T04:14:00.237724Z","iopub.status.idle":"2023-01-29T04:14:00.238310Z","shell.execute_reply.started":"2023-01-29T04:14:00.238020Z","shell.execute_reply":"2023-01-29T04:14:00.238047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_to_features(image_array):\n    \"\"\"\n    Convert an image array of the form (color band, height, width) to a\n    1-dimensional list of features. Returns a list where the first three\n    values are the averages of each color band, and the second three\n    values are the medians of each color band.\n    \"\"\"\n    averages = image_array.mean(axis=(1, 2)).tolist()\n    medians = np.median(image_array, axis=(1, 2)).tolist()\n\n    return averages + medians","metadata":{"id":"Lt8kdhH-jmgZ","execution":{"iopub.status.busy":"2023-01-29T04:14:00.237724Z","iopub.status.idle":"2023-01-29T04:14:00.238310Z","shell.execute_reply.started":"2023-01-29T04:14:00.238020Z","shell.execute_reply":"2023-01-29T04:14:00.238047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save image arrays in case we want to generate more features\nIMAGE_ARRAY_DIR = work_path\n# take a random subset of the training data for the benchmark\ntrain_subset = metadata[metadata[\"split\"] == \"train\"].sample(n=2500, random_state=2)\n\n# combine train subset with all test data\nmetadata_subset = pd.concat([train_subset, metadata[metadata[\"split\"] == \"test\"]])\nmetadata_subset.split.value_counts(dropna=False)","metadata":{"id":"wqfg6j1sm4-C","execution":{"iopub.status.busy":"2023-01-29T04:14:00.239758Z","iopub.status.idle":"2023-01-29T04:14:00.240593Z","shell.execute_reply.started":"2023-01-29T04:14:00.240051Z","shell.execute_reply":"2023-01-29T04:14:00.240077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this cell takes a LONG time because it iterates over all data!\n\n# save outputs in dictionaries\nselected_items = {}\nfeatures_dict = {}\nerrored_ids = []\n\n\nfor row in tqdm(metadata_subset.itertuples(), total=len(metadata_subset)):\n    pass\n    print (f'Getting image from row {row.index} out of {len(metadata_subset)}')\n    # check if we've already saved the selected image array\n    image_array_pth = IMAGE_ARRAY_DIR / f\"{row.uid}.npy\"\n\n    if image_array_pth.exists():\n        with open(image_array_pth, \"rb\") as f:\n            image_array = np.load(f)\n\n        # convert image to 1-dimensional features\n        image_features = image_to_features(image_array)\n        features_dict[row.uid] = image_features\n\n    # search and load the image array if not\n    else:\n        try:\n            ## QUERY STAC API\n            # get query ranges for location and date\n            search_bbox = get_bounding_box(\n                row.latitude, row.longitude, meter_buffer=50000\n            )\n            date_range = get_date_range(row.date, time_buffer_days=15)\n\n            # search the planetary computer\n            search = catalog.search(\n                collections=[\"sentinel-2-l2a\", \"landsat-c2-l2\"],\n                bbox=search_bbox,\n                datetime=date_range,\n            )\n            items = [item for item in search.get_all_items()]\n\n            ## GET BEST IMAGE\n            if len(items) == 0:\n                pass\n            else:\n                best_item, item_platform, item_date = select_best_item(\n                    items, row.date, row.latitude, row.longitude\n                )\n                # add to dictionary tracking best items\n                selected_items[row.uid] = {\n                    \"item_object\": best_item,\n                    \"item_platform\": item_platform,\n                    \"item_date\": item_date,\n                }\n\n            ## CONVERT TO FEATURES\n            # get small bbox just for features\n            feature_bbox = get_bounding_box(\n                row.latitude, row.longitude, meter_buffer=100\n            )\n\n            # crop the image\n            if \"sentinel\" in item_platform.lower():\n                image_array = crop_sentinel_image(best_item, feature_bbox)\n            else:\n                image_array = crop_landsat_image(best_item, feature_bbox)\n\n            # save image array so we don't have to rerun\n            with open(image_array_pth, \"wb\") as f:\n                np.save(f, image_array)\n\n            # convert image to 1-dimensional features\n            image_features = image_to_features(image_array)\n            features_dict[row.uid] = image_features\n\n        # keep track of any that ran into errors without interrupting the process\n        except:\n            errored_ids.append(row.uid)","metadata":{"id":"To46OOVlnBUp","execution":{"iopub.status.busy":"2023-01-29T04:14:00.242969Z","iopub.status.idle":"2023-01-29T04:14:00.243392Z","shell.execute_reply.started":"2023-01-29T04:14:00.243196Z","shell.execute_reply":"2023-01-29T04:14:00.243215Z"},"trusted":true},"execution_count":null,"outputs":[]}]}